{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"C:\\\\Users\\\\Admin\\\\Desktop\\\\RoboVision\\\\image_color.jpg\",cv2.IMREAD_COLOR)\n",
    "cv2.imshow(\"image\",img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "A = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\black_dot.jpg\",cv2.IMREAD_COLOR)\n",
    "cv2.imshow(\"A\",A)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "Lh = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\horizontal_line.jpg\",cv2.IMREAD_COLOR)\n",
    "cv2.imshow(\"Lh\",Lh)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "Lv = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\vertical_line.jpg\",cv2.IMREAD_COLOR)\n",
    "cv2.imshow(\"Lv\",Lv)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "Ldp = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\positive_45.jpg\",cv2.IMREAD_COLOR)\n",
    "cv2.imshow(\"Ldp\",Ldp)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "Ldn = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\slanted_negative45.jpg\",cv2.IMREAD_COLOR)\n",
    "cv2.imshow(\"Ldn\",Ldn)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial coordinates are:  (-1000, 155)   (999, 156)  \n",
      "Spatial coordinates are:  (-1000, 164)   (999, 165)  \n",
      "The orientation is:  0.0005002500833333083\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "Lh = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\horizontal_line.jpg\",cv2.IMREAD_COLOR)\n",
    "cv2.imshow(\"Lh\",Lh)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "gray = cv2.cvtColor(Lh, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "lines = cv2.HoughLines(edges, 1, np.pi/180, 200)\n",
    "\n",
    "for r_theta in lines:\n",
    "    arr = np.array(r_theta[0], dtype=np.float64)\n",
    "    r, theta = arr\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*r\n",
    "    y0 = b*r\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "\n",
    "    cv2.line(Lh, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    print(\"Spatial coordinates are: \",(x1,y1),\" \",(x2,y2),\" \")\n",
    "print(\"The orientation is: \",math.atan((y2-y1)/(x2-x1)))  \n",
    "\n",
    "cv2.imwrite('linesDetected_Lh.jpg', Lh)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#import numpy as np\n",
    "A_gray = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\blackdot_matrix.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow(\"A_gray\",A_gray)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "Lh_gray = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\horizontal_line.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow(\"Lh_gray\",Lh_gray)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "Lv_gray = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\vertical_line.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow(\"Lv_gray\",Lv_gray)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "Ldp_gray = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\positive_45.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow(\"Ldp_gray\",Ldp_gray)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "Ldn_gray = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\slanted_negative45.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow(\"Ldn_gray\",Ldn_gray)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\VSC_workspace\\robot_vision_lab\\Lab5\\RoboVision\\Lab5_robovison.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/VSC_workspace/robot_vision_lab/Lab5/RoboVision/Lab5_robovison.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m edges \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mCanny(gray, \u001b[39m50\u001b[39m, \u001b[39m150\u001b[39m, apertureSize\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/VSC_workspace/robot_vision_lab/Lab5/RoboVision/Lab5_robovison.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m lines \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mHoughLines(edges, \u001b[39m1\u001b[39m, np\u001b[39m.\u001b[39mpi\u001b[39m/\u001b[39m\u001b[39m180\u001b[39m, \u001b[39m200\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/VSC_workspace/robot_vision_lab/Lab5/RoboVision/Lab5_robovison.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m r_theta \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/VSC_workspace/robot_vision_lab/Lab5/RoboVision/Lab5_robovison.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(r_theta[\u001b[39m0\u001b[39m], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/VSC_workspace/robot_vision_lab/Lab5/RoboVision/Lab5_robovison.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     r, theta \u001b[39m=\u001b[39m arr\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "Lh = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\black_dot.jpg\",cv2.IMREAD_COLOR)\n",
    "cv2.imshow(\"Lh\",Lh)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "gray = cv2.cvtColor(Lh, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "lines = cv2.HoughLines(edges, 1, np.pi/180, 200)\n",
    "\n",
    "for r_theta in lines:\n",
    "    arr = np.array(r_theta[0], dtype=np.float64)\n",
    "    r, theta = arr\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*r\n",
    "    y0 = b*r\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "\n",
    "    cv2.line(Lh, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    print(\"Spatial coordinates are: \",(x1,y1),\" \",(x2,y2),\" \")\n",
    "print(\"The orientation is: \",math.atan((y2-y1)/(x2-x1)))  \n",
    "\n",
    "cv2.imwrite('linesDetected_Lh.jpg', Lh)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial coordinates are:  (302, 1000)   (302, -1000)  \n",
      "Spatial coordinates are:  (324, 1000)   (324, -1000)  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "Lv = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\vertical_line.jpg\",cv2.IMREAD_COLOR)\n",
    "cv2.imshow(\"Lv\",Lv)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "gray = cv2.cvtColor(Lv, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "lines = cv2.HoughLines(edges, 1, np.pi/180, 200)\n",
    "\n",
    "for r_theta in lines:\n",
    "    arr = np.array(r_theta[0], dtype=np.float64)\n",
    "    r, theta = arr\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*r\n",
    "    y0 = b*r\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "\n",
    "    cv2.line(Lv, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    print(\"Spatial coordinates are: \",(x1,y1),\" \",(x2,y2),\" \")\n",
    "#print(\"The orientation is: \",math.atan((y2-y1)/(x2-x1)))  \n",
    "#The orientation will be atan of pi/2 which will be undefined and throw an error\n",
    "\n",
    "cv2.imwrite('linesDetected_Lv.jpg', Lv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial coordinates are:  (-512, 901)   (901, -512)  \n",
      "Spatial coordinates are:  (-502, 911)   (911, -502)  \n",
      "The orientation is:  0.7853981633974483\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "Ldp = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\positive_45.jpg\",cv2.IMREAD_COLOR)\n",
    "cv2.imshow(\"Ldp\",Ldp)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "gray = cv2.cvtColor(Ldp, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "lines = cv2.HoughLines(edges, 1, np.pi/180, 200)\n",
    "\n",
    "for r_theta in lines:\n",
    "    arr = np.array(r_theta[0], dtype=np.float64)\n",
    "    r, theta = arr\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*r\n",
    "    y0 = b*r\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "\n",
    "    cv2.line(Ldp, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    print(\"Spatial coordinates are: \",(x1,y1),\" \",(x2,y2),\" \")\n",
    "print(\"The orientation is: \",math.atan(abs((y2-y1)/(x2-x1))))  \n",
    "\n",
    "cv2.imwrite('linesDetected_Ldp.jpg', Ldp)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial coordinates are:  (-702, -711)   (711, 702)  \n",
      "Spatial coordinates are:  (-710, -703)   (703, 710)  \n",
      "The orientation is:  0.7853981633974483\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "Ldn = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\slanted_negative45.jpg\",cv2.IMREAD_COLOR)\n",
    "cv2.imshow(\"Ldn\",Ldn)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "gray = cv2.cvtColor(Ldn, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "lines = cv2.HoughLines(edges, 1, np.pi/180, 200)\n",
    "\n",
    "for r_theta in lines:\n",
    "    arr = np.array(r_theta[0], dtype=np.float64)\n",
    "    r, theta = arr\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*r\n",
    "    y0 = b*r\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "\n",
    "    cv2.line(Ldn, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    print(\"Spatial coordinates are: \",(x1,y1),\" \",(x2,y2),\" \")\n",
    "print(\"The orientation is: \",math.atan(abs((y2-y1)/(x2-x1))))  \n",
    "\n",
    "cv2.imwrite('linesDetected_Ldn.jpg', Ldn)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "A_gray = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\black_dot.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow(\"A_gray\",A_gray)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "kernel = np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]])\n",
    "#print(kernel)\n",
    "\n",
    "A_gray_conv = cv2.filter2D(A_gray,-1,kernel)\n",
    "cv2.imshow(\"Convoluted A image\",A_gray_conv)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "Lh_gray = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\horizontal_line.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow(\"Lh_gray\",Lh_gray)\n",
    "cv2.waitKey(0)\n",
    "kernel = np.array([[-1,-1,-1],[2,2,2],[-1,-1,-1]])\n",
    "#print(kernel)\n",
    "\n",
    "Lh_gray_conv = cv2.filter2D(Lh_gray,-1,kernel)\n",
    "cv2.imshow(\"Convoluted Lh image\",Lh_gray_conv)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "Lv_gray = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\vertical_line.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow(\"Lv_gray\",Lv_gray)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "kernel = np.array([[-1,2,-1],[-1,2,-1],[-1,2,-1]])\n",
    "#print(kernel)\n",
    "\n",
    "Lv_gray_conv = cv2.filter2D(Lv_gray,-1,kernel)\n",
    "cv2.imshow(\"Convoluted Lv image\",Lv_gray_conv)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "Ldp_gray = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\positive_45.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow(\"Ldp_gray\",Ldp_gray)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "kernel = np.array([[-1,-1,2],[-1,2,-1],[2,-1,-1]])\n",
    "#print(kernel)\n",
    "\n",
    "Ldp_gray_conv = cv2.filter2D(Ldp_gray,-1,kernel)\n",
    "cv2.imshow(\"Convoluted Ldp image\",Ldp_gray_conv)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "Ldn_gray = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\slanted_negative45.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow(\"Ldn_gray\",Ldn_gray)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "kernel = np.array([[2,-1,-1],[-1,2,-1],[-1,-1,2]])\n",
    "#print(kernel)\n",
    "\n",
    "Ldn_gray_conv = cv2.filter2D(Ldn_gray,-1,kernel)\n",
    "cv2.imshow(\"Convoluted Ldn image\",Ldn_gray_conv)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n",
      "252\n",
      "254\n",
      "246\n",
      "246\n",
      "246\n",
      "254\n",
      "248\n",
      "244\n",
      "254\n",
      "247\n",
      "250\n",
      "244\n",
      "246\n",
      "248\n",
      "246\n",
      "249\n",
      "254\n",
      "253\n",
      "250\n",
      "254\n",
      "229\n",
      "242\n",
      "254\n",
      "247\n",
      "179\n",
      "12\n",
      "4\n",
      "0\n",
      "155\n",
      "231\n",
      "244\n",
      "248\n",
      "248\n",
      "182\n",
      "16\n",
      "0\n",
      "0\n",
      "6\n",
      "0\n",
      "139\n",
      "247\n",
      "254\n",
      "244\n",
      "216\n",
      "11\n",
      "0\n",
      "1\n",
      "13\n",
      "0\n",
      "0\n",
      "10\n",
      "249\n",
      "253\n",
      "240\n",
      "249\n",
      "2\n",
      "3\n",
      "20\n",
      "0\n",
      "5\n",
      "0\n",
      "2\n",
      "251\n",
      "254\n",
      "245\n",
      "246\n",
      "240\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "7\n",
      "0\n",
      "248\n",
      "250\n",
      "154\n",
      "3\n",
      "0\n",
      "8\n",
      "11\n",
      "0\n",
      "0\n",
      "251\n",
      "250\n",
      "249\n",
      "251\n",
      "224\n",
      "138\n",
      "2\n",
      "0\n",
      "0\n",
      "12\n",
      "183\n",
      "241\n",
      "254\n",
      "250\n",
      "253\n",
      "251\n",
      "248\n",
      "254\n",
      "236\n",
      "245\n",
      "254\n",
      "253\n",
      "247\n",
      "249\n",
      "248\n",
      "251\n",
      "235\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "A_gray = cv2.imread(\"E:\\\\VSC_workspace\\\\robot_vision_lab\\\\Lab5\\\\RoboVision\\\\black_dot.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow(\"A_gray\",A_gray)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(A_gray)\n",
    "\n",
    "for i in A_gray:\n",
    "    for j in i:\n",
    "        if(j!=255):\n",
    "            print(j)\n",
    "\n",
    "\n",
    "\n",
    "#kernel = np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]])\n",
    "#print(kernel)\n",
    "\n",
    "#A_gray_conv = cv2.filter2D(A_gray,-1,kernel)\n",
    "#cv2.imshow(\"Convoluted A image\",A_gray_conv)\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69963ce38df6fcf92bf4af08071b19a91e53213176803e31030a37c126f9cefb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
